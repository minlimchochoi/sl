---
layout: default
---
<div class="row">
  <div class="col-sm-12 col-md-6">
    <div class="well-sm">
      <h3>All of <span style="color:blue">S</span>tatistical <span style="color:blue">L</span>earning</h3>
      <p> by <span style="color:blue">S</span>ungbin <span style="color:blue">L</span>im </p>
      <p>
 	      <img src="profile_0.png" width=170 height=170>
      </p>
      <p>
 	      <a href="https://www.dropbox.com/s/huik76zchc9n5dl/CV_sungbin.pdf?dl=0" target="_blank">
	        <button type="button" class="btn btn-success">CV</button>
	      </a>
      </p>
    </div>
    
    <div class="well-sm">
      <h3>New Posts</h3>
      <ul class="post-list">
	      {% for post in site.posts limit:3 %}
	      <li>
	        <h4>
            <a href="{{ post.url | prepend: site.baseurl }}">{{ post.title }}</a>
	        </h4>
	        <p><span class="post-date">{{ post.date | date: "%b %-d, %Y" }}</span></p>
	        {{ post.excerpt }}
          <hr/>          
	      </li>
	      {% endfor %}
      </ul>
    </div>
  </div>
  
  <div class="col-sm-12 col-md-6">
    <div class="well-sm">
      <h3>1. Analytic approach to Generative Models</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/agm/0"> 1. Generative Adversarial Nets (GAN)</a></li>
        <li><a href="{{ site.baseurl }}/docs/agm/1"> 2. Variational Auto-Encoder (VAE)</a></li>
      </ul>
    </div>
    <div class="well-sm">
      <h3>2. All of Statistics</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/aos/0"> Part 1. Probability Theory </a></li>
        <li><a href="{{ site.baseurl }}/docs/aos/1"> Part 2. Statistical Inference </a></li>
        <li><a href="{{ site.baseurl }}/docs/aos/2"> Part 3. Statistical Models and Methods </a></li>
      </ul>
    </div>
    <div class="well-sm">
      <h3>3. All of Nonparametric Statistics</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/aons/0"> 1. Introduction </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/1"> 2. Estimating the CDF and Statistical Functionals </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/2"> 3. The Bootstrap and the Jacknife</a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 4. Smoothing: General Concepts </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 5. Nonparametric Regression </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 6. Density Estimation </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 7. Normal Means and Minimax Theory </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 8. Nonparametric Inference Using Orthogonal Functions </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 9. Wavelets and Other Adaptive Methods </a></li>
        <li><a href="{{ site.baseurl }}/docs/aons/3"> 10 Other Topics</a></li>
      </ul>
    </div>
    <div class="well-sm">
      <h3>4. Elements of Statistical Learning</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/esl/0"> 1. Introduction</a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/1"> 2. Overview of Supervised Learning </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/2"> 3. Linear Methods for Regression </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/3"> 4. Linear Methods for Classification </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/4"> 5. Basic Expansions and Regularization </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/5"> 6. Kernel Smoothing Methods </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/6"> 7. Model Assessment and Selection </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 8. Model Inference and Averaging </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 9. Additive Models, Trees, and Related Methods </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 10. Boosting and Additive Trees </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 11. Neural Networks </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 12. Support Vector Machines and Flexible Discriminants </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 13. Prototype Methods and Nearest-Neighbors </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 14. Unsupervised Learning </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 15. Random Forests </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 16. Ensemble Learning </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 17. Undirected Graphical Models </a></li>
	<li><a href="{{ site.baseurl }}/docs/esl/7"> 18. High-Dimensional Problems </a></li>
      </ul>
    </div>

    <div class="well-sm">
      <h3>5. Modern Probability Theory</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/mpt/0">0. Kolmogorov Probability Axiom </a></li>
        <li><a href="{{ site.baseurl }}/docs/mpt/1">1. Basic Measure Theory </a></li>
        <li><a href="{{ site.baseurl }}/docs/mpt/2">2. Gaussian Processes </li>
        <li><a href="{{ site.baseurl }}/docs/mpt/3">3. Markov Theory </li>
        <li><a href="{{ site.baseurl }}/docs/mpt/4">4. Stochastic Calculus </li> 
      </ul>
    </div>



    
  </div>
</div>



