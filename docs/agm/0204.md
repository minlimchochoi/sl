---
layout: page-sidenav
group: "VAE"
title: "4. Reparametrization Trick"
---


- [GAN (Goodfellow *et al*, 2014)](https://arxiv.org/abs/1406.2661) 논문 요약 설명
- Minimax game 을 토대로 한 generative model (이하 **GM**) 을 이해한다

### 미리 알아두면 좋은 용어들

- [Minimax Game](https://en.wikipedia.org/wiki/Minimax)
- [Nash Equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium)
- [Saddle Point](https://en.wikipedia.org/wiki/Saddle_point)
- [Change of variable formula](https://math.stackexchange.com/questions/152338/is-there-a-change-of-variables-formula-for-a-measure-theoretic-integral-that-doe)

---
## What is GAN? 
- GAN 은 GM 의 한 종류 (GM 의 분류는 [Preface](https://sungbinlim.github.io/sl/docs/agm/0) 참조)
- GAN 은 

#### GAN 의 알려진 장점

1. GAN 은 sample 을 parallel 하게 생성할 수 있으므로 \\( \mathbf{x} = (x_{1},\ldots,x_{n})\\) 의 dimension \\(n\\) 에 비례해서 런타임이 증가하는 Fully Visible Belief Network (**FVBN**) 보다 빠르다. 
2. Boltzmann machine (**BM**) 이나 Nonlinear Independent Component Analysis (**ICA**) 에 비해 Generator function 에 거의 제약을 걸지 않는다. 
3. Markov chain 을 쓰지 않는다. 
4. Variational bound 이나 특정 model family (e.g. mean-field family) 를 쓰지 않는다. GAN 은 asymptotically consistent 하다. 이는 Variational Auto-Encoder (**VAE**) 에 비해 확실한 장점이다.
	- Asymptotically consistency 에 대해선 Proposition 2 를 참조한다
5.


$$
V(D,G) = \mathbb{E}_{x\sim p_{\text{data}}(x)}[\log D(x)]+\mathbb{E}_{z \sim p_{Z}(z)}[\log (1-D(z))]
$$

GAN 은 위의 \\(V(D,G)\\) 를 이용하여 [최소-최대 문제](https://en.wikipedia.org/wiki/Minimax) 를 푸는 것을 목적으로 한다

$$
\min_{G}\max_{D} V(D,G)
$$

---



---
#
### 참고자료

- [2016 NIPS Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
- [](https://anujdutt9.github.io/GAN-PI.html)
- [유재준님 블로그](http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html#more)