---
layout: page-sidenav
group: "Models, Statistical Inference and Learning"
title: "3. Fundamental Concepts in Inference"
---

- 상당수의 추론 문제는 estimation, confidence sets, hypothesis testing 으로 구분할 수 있다
- `Notation` : Parametric model \\( \mathfrak{F} = \{ f(x;\theta):\theta\in\theta \}\\) 에 대해, 확률 또는 기대값의 밑첨자로 \\( \theta \\) 가 사용되는 경우 \\( f(x;\theta) \\) 를 밀도함수로 사용하는 \\( x \\) 대한 적분으로 간주한다 (절대 \\( \theta \\) 에 대한 적분이 아님). 가령 다음과 같은 방식으로 표기한다:

$$
\mathbb{P}_{\theta}(X\in A) = \int_{A} f(x;\theta)dx,\quad \mathbb{E}_{\theta}(r(X)) = \int r(x)f(x;\theta)dx
$$

$$
\mathbb{V}_{\theta}(g(X)) = \int |g(x)|^{2} f(x;\theta)dx-\left(\int g(x)f(x;\theta)dx \right)^{2}
$$

## Point estimation

- 점추정(point estimation)은 어떤 대상의 양(quantity)을 "best guess" 하나로 추정하는 걸 말한다
- 점추정은 다양한 대상을 가지고 적용할 수 있는데 가령 parametric model \\( \mathfrak{F} \\) 의 parameter 나, CDF \\( F \\), PDF \\( f \\), regression function \\( r \\), prediction 에서 \\( Y \\) 의 값 등이 될 수 있다
- `Convention` : 앞으로 unknown parameter \\( \theta \\) 에 대한 점추정은 \\( \hat{\theta} \\) 또는 \\( \hat{\theta}_{n} \\) 으로 표기한다. \\( \hat{\theta} \\) 은 데이터에 따라 달라질 수 있으므로 확률변수이다
- 점추정은 수학적으로는 다음과 같이 쓸 수 있다. 분포 \\( F \\) 에서 [i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) 로 추출된 \\( n \\) 개의 데이터 \\( X_{1},\ldots, X_{n} \\) 가 있다고 했을 때, parameter \\( \theta \\) 의 점추정 \\( \hat{\theta}_{n} \\) 은 \\( X_{1},\ldots, X_{n} \\) 에 대한 함수이다:

$$
\hat{\theta}_{n} = g(X_{1},\ldots, X_{n})
$$

- 점추정에 대한 Bias 는 다음과 같이 정의한다 (위의 `Notation` 참조)

$$
\text{bias}(\hat{\theta}_{n})=\mathbb{E}_{\theta}(\hat{\theta}_{n})-\theta = \int \hat{\theta}_{n}(x) f(x;\theta)dx-\theta
$$

- 만약 \\( \text{bias}(\hat{\theta}_{n}) = 0 \\) 이라면 (즉, \\( \mathbb{E}_{\theta}(\hat{\theta}_{n}) = \theta \\) ) 우리는 \\( \hat{\theta}_{n} \\) 이 **불편향(unbiased)** 되었다고 말한다
- `Comment` : 불편향성은 과거만큼 중요하게 여기지 않는다 (일부 머신러닝 연구자들은 신경조차 쓰지도 않는다). 왜냐하면 실용적으로 사용되는 대부분의 추정량(estimator) 이 편향되어 있기 때문이다. 
- 불편향성을 포기하는 대신 데이터를 모으면 모을수록 (즉, \\( n \to \infty \\) 일수록) 점추정 \\( \hat{\theta}_{n} \\) 이 원래의 true parameter \\( \theta \\) 로 [확률수렴(converge in probability)](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability)하는 성질은 가지길 원한다. 이 성질을 **일치성(consistency)** 이라 한다

---

`Definition`. Parameter \\( \theta \\) 의 점추정 \\( \hat{\theta}_{n} \\) 이 \\( \theta \\) 로 확률수렴(converge in probability)하면 일치성(consistency)을 가진다고 말한다

---

- 추정량 \\( \hat{\theta}_{n} \\) 의 분포를 **표본분포(sampling distribution)** 이라 부른다. \\( \hat{\theta}_{n} \\) 의 표준편차(standard deviation) 을 **표준오차(standard error)** 라 하고 \\( \text{se} \\) 로 표기한다 :

$$
\text{se}(\hat{\theta}_{n})=\sqrt{\mathbb{V}_{\theta}(\hat{\theta}_{n})} = \sqrt{\int |\hat{\theta}_{n}(x)|^{2}F(dx)-\left(\int \hat{\theta}_{n}(x)F(dx) \right)^{2}}
$$

- 표준오차 \\( \text{se} \\) 는 CDF \\( F \\) 에 대한 statistical functional 이므로 사실 unknown quantity 지만 추정이 가능하다. 표준오차 \\( \text{se} \\) 의 추정량을 \\( \hat{\text{se}} \\) 이라 한다
- `Example`. \\( X_{1},\ldots, X_{n} \\) 이 베르누이 분포(\\( p \\))를 따른다고 하고 \\( \hat{p}_{n} = \frac{\sum_{i}X_{i}}{n} \\) 라 하자. 이 경우 \\( \mathbb{E}(\hat{p}_{n}) = \frac{\sum_{n}\mathbb{E}(X_{i})}{n} = \frac{np}{n}=p \\) 이므로 점추정 \\( \hat{p}_{n} \\) 은 unbiased 이다. 이 때 표준오차와 표준오차의 추정량은 다음과 같다 [증명참조](https://sungbinlim.github.io/sl/proof/aos2/010301.pdf) :

$$
\text{se} = \sqrt{\mathbb{V}(\hat{p}_{n})} = \sqrt{\frac{p(1-p)}{n}}
$$

$$
\hat{\text{se}}=\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
$$

